##############
# Timer code #
##############

!!! DRAFT-DRAFT-DRAFT-DRAFT-DRAFT-DRAFT-DRAFT-DRAFT-DRAFT-DRAFT-DRAFT !!!

Requirements:
*************

R10: An instance of an object must be able to register to get a single notification (a timeout) after at least 10s and a best effort must be made to to make the timeout after no more than 30s (unless a special condition happens as defined later in this requirement list)

R20: During shutdown all registered instances must get a timeout, even if the 10s delay has not been reached (but only if they haven't gotten one previously)

R30: The number of notifications registered in one inspector context must not limit the number of registrations that can be done in another inspector context

R32: If an inspector context can't hold any more registrations the specific contexts queue might be flushed, invalidating items younger than 10s, if that doesn't atomically creates on opening for a new registration, the timer being registered must immediately expire (flushing can continue in the background to make space for future registrations)

R40: An instance should be able to cancel it's timeout, performing this cancellation must return if the timer was running (has not elapsed or been previously canceled)

R50: Handling a timeout must not block registrations from other threads

R60: Registration and cancellation of timeouts must be done in constant O(1) time, except cancellation of a timeout might block until an active timeout on the same object has completed

Requirement notes:
******************

N100: It is not a requirement that a timeout happens on the same thread as the registration for the timeout did

N110: It is not a requirement that an instance can reset or restart the timer

N120: It is not a requirement that a thread can registrate for a new timeout while the same thread is handling a timeout (i.e. the timeout code directly or indirectly registers for a new timeout)

N130: It is not a requirement that a thread can cancel an existing timeout while the same thread is handling a timeout (i.e. the timeout code directly or indirectly cancels the same or another timeout)

N140: From R32 and N130 follows that a instance must be able to handle the timer expiring either from the same or a different thread, while the registration or a cancellation is taking place (i.e. handling a timeout must not use resources reserved during the registration or cancellation)

N150: It is not a requirement that the cancel functionality can be operated from multiple threads at the same time


Discussion
**********

The following is a short description of the ideas that were considered for this design.

Idea A
------

Three containers are created (for each inspector context):
	- A collecting where new registrations are added
	- A waiting where registrations wait until we are sure they are at least 10s old
	- An expiring where registrations we know are older than 10s are kept, while we work on expiring them

The idea is then that every 10s we look at the expiring and if we have finished emptying it, we rotate the containers, so the now empty expiring container becomes the collecting, the old collecting becomes the waiting that the waiting becomes the expiring that we start to empty.  If the expiring wasn't empty, we just continue our process of emptying it, but don't swap the containers.

Main benefit of this solution is that the removal of elements doesn't require locking of the collecting container, assuming we can invalidate canceled instances without taking such a lock, e.g. if canceled elements can remain in the container in an invalid state

Idea B
------

For each inspector context a single FIFO queue is used (C++ std::queue based on std::deque) where new elements are added at one end and removed from the other on each 10s timer tick

This is very similar to Idea A, except we only run in a single list, the downside is that while iterators stay valid during adding/removing of elements we still need to lock the list when we add or remove elements.  It could lead to a general lower memory consumption runtime, as it would be possible to shrink the list from the end on cancellation/expiry of the last element in the list.

Idea C
------

A circular buffer where registrations are added and removed, in principle the same as B except the buffer-space is preallocated.

Assuming we will use one of the the std. C++ containers as storage (e.g. std::array or std::vector) and use container functions that does range checking, it should be relative safe with respect to memory access - there is also the possibility of using boost circular_buffer.

NOTE: Be careful with std::memory_order for the atomics here

For illustration lets assume we have a circular list with 5 elements, the only value not being an atomic is the pointer.  The value of the start index is always the modulus of the index so (start%5) in this case, this gives us the circular behavior, see below for details on how wrap-around of the underlying pointer is handled.

Count=0                 // Count of occupied elements (atomic)
NxtFree-------v         // The next element that should be taken (atomic)
T0------------v         // The value of NxtFree at last system timer tick
T10-----------v         // The value of NxtFree at 2 system timer tick's ago
NxtClear------v         // The next element that should be cleared if Count>0
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # Pending # Pending # Pending # Pending # Pending #  // Either "Pending" or "In use" (atomic)
         # Passive # Passive # Passive # Passive # Passive #  // Either "Passive" or "Running" (atomic)
         # nullptr # nullptr # nullptr # nullptr # nullptr #  // Pointer back to the timeout element
         ###################################################
(Note: Passive and nullptr can be merged to one in an actual implementation)

When a new entry (from any thread) is added, we first need to make a reservation, so we use fetch_add to increase the count:

count=1
NxtFree-------v
T0------------v
T10-----------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # Pending # Pending # Pending # Pending # Pending #
         # Passive # Passive # Passive # Passive # Passive #
         # nullptr # nullptr # nullptr # nullptr # nullptr #
         ###################################################

If the value we got back from fetch_add is greater than the list size (5 in our case) we decrease it again (we don't care about the value after the decrease) and go to the buffer full handling (R32)

We now know that there is a slot in the buffer for us, to get our slot assigned (0 in this example) we do fetch_add on NxtFree:

count=1
NxtFree-----------------v
T0------------v
T10-----------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # Pending # Pending # Pending # Pending # Pending #
         # Passive # Passive # Passive # Passive # Passive #
         # nullptr # nullptr # nullptr # nullptr # nullptr #
         ###################################################

If another thread now does something similar they will get another free slot, if someone had beaten us, we would get the next free slot - we did the reservation by increasing the count at the beginning, so we are sure we will get a free one.

We now own slot 0 and can set it to Running and set the pointer back to our notification element - as long as we don't change the "Pending" to "In use" we are sure the object won't be reused or expired.

count=1
NxtFree-----------------v
T0------------v
T10-----------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # Pending # Pending # Pending # Pending # Pending #
         # Running # Passive # Passive # Passive # Passive #
         # 0x1234  # nullptr # nullptr # nullptr # nullptr #
         ###################################################

0x1234->exp: false
0x1234->idx: 0

We now store the -0- index in the notification element, indicating to the notification element that it now has a running timer, we also mark it as in use in the buffer:

count=1
NxtFree-----------------v
T0------------v
T10-----------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # In use  # Pending # Pending # Pending # Pending #
         # Running # Passive # Passive # Passive # Passive #
         # 0x1234  # nullptr # nullptr # nullptr # nullptr #
         ###################################################

0x1234->exp: false
0x1234->idx: 0

Time now passes and let's say after some time the buffer looks like:

count=4
NxtFree-----------------------------------------------v
T0------------v
T10-----------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # In use  # In use  # Pending # In use  # Pending #
         # Running # Running # Passive # Running # Passive #
         # 0x1234  # 0xABCD  # nullptr # 0x3333  # nullptr #
         ###################################################

0x1234->exp: false
0x1234->idx: 0

We now have the first 4 slots in use (count is 4), the thread who made the reservation for slot 2 has for some reason not finished, but it has the reservation from when it increased the count

Let's say we now cancel on slot (0), the race condition we need to handle is if there is a timer expiring around the same time.

We take the most common case first, which is we are nowhere near a timeout, so cancel is just being called.

First the local exp is set to true, indicating the timer is no longer running

count=4
NxtFree-----------------------------------------------v
T0------------v
T10-----------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # In use  # In use  # Pending # In use  # Pending #
         # Running # Running # Passive # Running # Passive #
         # 0x1234  # 0xABCD  # nullptr # 0x3333  # nullptr #
         ###################################################

0x1234->exp: true
0x1234->idx: 0

After this is set, we go to the 0 index in the buffer, do an exchange on the "Running", moving it to "Passive", we don't touch any of the other fields, if the value we got form the exchange was Running, all is good and we can return a successful cancellation (R40) - we don't

count=4
NxtFree-----------------------------------------------v
T0------------v
T10-----------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # In use  # In use  # Pending # In use  # Pending #
         # Passive # Running # Passive # Running # Passive #
         # 0x1234  # 0xABCD  # nullptr # 0x3333  # nullptr #
         ###################################################

0x1234->exp: true
0x1234->idx: 0

The next case we look into is that we are doing a timeout, with no cancellation anywhere near.  Let's reset our state:

count=4
NxtFree-----------------------------------------------v
T0------------v
T10-----------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # In use  # In use  # Pending # In use  # Pending #
         # Running # Running # Passive # Running # Passive #
         # 0x1234  # 0xABCD  # nullptr # 0x3333  # nullptr #
         ###################################################

0x1234->exp: false
0x1234->idx: 0

Now let's say 10s passed from the beginning, we get a system timer tick (Assume this code is mutex protected, so we can force an expiry as needed by(R32).), a system timer tick means we shift T0 to T10, as NxtClear equals the old T10 we just copy NxtFree to T0.

count=4
NxtFree-----------------------------------------------v
T0----------------------------------------------------v
T10-----------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # In use  # In use  # Pending # In use  # Pending #
         # Running # Running # Passive # Running # Passive #
         # 0x1234  # 0xABCD  # nullptr # 0x3333  # nullptr #
         ###################################################

0x1234->exp: false
0x1234->idx: 0

Another 10s needs to elapse before the state changes, as we do a new shift of T0 and T10, again putting the current value of NxtFree into T0:

count=4
NxtFree-----------------------------------------------v
T0----------------------------------------------------v
T10---------------------------------------------------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # In use  # In use  # Pending # In use  # Pending #
         # Running # Running # Passive # Running # Passive #
         # 0x1234  # 0xABCD  # nullptr # 0x3333  # nullptr #
         ###################################################

0x1234->exp: false
0x1234->idx: 0

As T10 is now different than NxtClear we start to expire timers.

We look at the element NxtClear points to, and try to move it to the passive state, reading the old value out in the process.

count=4
NxtFree-----------------------------------------------v
T0----------------------------------------------------v
T10---------------------------------------------------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # In use  # In use  # Pending # In use  # Pending #
         # Passive # Running # Passive # Running # Passive #
         # 0x1234  # 0xABCD  # nullptr # 0x3333  # nullptr #
         ###################################################

0x1234->exp: false
0x1234->idx: 0

The notification is then made on the pointer stored, after the notification is completed the exp filed will be set (if it was already set, there is a racecondition), so future calls to cancel will just return without touching the record.

count=4
NxtFree-----------------------------------------------v
T0----------------------------------------------------v
T10---------------------------------------------------v
NxtClear------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # In use  # In use  # Pending # In use  # Pending #
         # Passive # Running # Passive # Running # Passive #
         # 0x1234  # 0xABCD  # nullptr # 0x3333  # nullptr #
         ###################################################

0x1234->exp: true
0x1234->idx: 0

Field 0 can now be recycled, NxtClear updated and the count decreased

count=3
NxtFree-----------------------------------------------v
T0----------------------------------------------------v
T10---------------------------------------------------v
NxtClear----------------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # Pending # In use  # Pending # In use  # Pending #
         # Passive # Running # Passive # Running # Passive #
         # nullptr # 0xABCD  # nullptr # 0x3333  # nullptr #
         ###################################################

0xABCD->exp: false
0xABCD->idx: 1

The exact same procedure is now done for field 1 as nxtClear != T10, let's just look at the end state:

count=2
NxtFree-----------------------------------------------v
T0----------------------------------------------------v
T10---------------------------------------------------v
NxtClear--------------------------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # Pending # Pending # Pending # In use  # Pending #
         # Passive # Passive # Passive # Running # Passive #
         # nullptr # nullptr # nullptr # 0x3333  # nullptr #
         ###################################################

We would stop here, as entry 2 is already in the pending state, we know this was because the thread who made a reservation for this field didn't complete yet (this is most likely an error as 20s has passed and that thread must be in the timer code, but it could also be that we were forced to do a couple of ticks if there weren't space for new entries).

If entry 2 hadn't been in the Pending state we would have continued emptying entry 2 and 3 until NxtClear reaches T10.

count=0
NxtFree-----------------------------------------------v
T0----------------------------------------------------v
T10---------------------------------------------------v
NxtClear----------------------------------------------v
         ####-0-#######-1-#######-2-#######-3-#######-4-####
         # Pending # Pending # Pending # Pending # Pending #
         # Passive # Passive # Passive # Passive # Passive #
         # nullptr # nullptr # nullptr # nullptr # nullptr #
         ###################################################

When cancellation and a timer tick overlap
------------------------------------------

In this section we will only look at a single element to cover how the algorithm will handle the case where there is a cancel at the same time as a timer tick.

The initial state is a running time entry:

Running (Run) : True
Expired (Exp) : False

There will be one Exp mutex for each timer instance/inspector instance

An expiery will:

* First set Running to False, (if Running was already False the cancellation would have been done)
* Do the notification on the object
* Try to set Exp to True, (if Exp was false, there wasn't a simultaneous cancel going on and we revert to normal behavior)
* When it finds that Exp was already True, it will know racecondition avoidance needs to take place
* It takes the timer Exp mutex, and waits for Exp to become false (i.e. the cancellation code has given up)
* When Exp has become false, it flips it to true and makes a notify_one on it.
* The expiry code is now done and can release the exp mutex

A cancellation will (note N150 states only one cancellation is supported at any given time):

* First set Exp to True, (if Exp was already True, element wouldn't be expected to exist and the cancel would return with a value indication the timer wasn't running (R40)
* It would set Running to False (if Running was True there wouldn't be any expiry on going, and the cancel could return a success (R40))
* As running was already false, it would know that a cancellation was in progress
* As Exp was set to true, but we couldn't cancel the timer, it needs to be reverted, so it must be flipped back to False, followed by a notify_one.
* We now need the expiry code to signal that it is done, so wait for Exp to become true again.
* after Exp is set to true, we need to ensure that the expiry code is done with us (it could have flipped exp before we executed our wait, and hence not have called notify_one yet) - we ensure it is out by trying to aquire the exp mutex (the expiery code would have taken this mutex before flipping Exp).
* when we get the exp mutex, we know the expiry is done, and we can release the mutex again and safely return with a value that the cancel call did not have any effect (R40)

---

NxtClear is usually only updated when the 10s system timer ticks - when it wraps around (so gets > 5 in our example), the length (5) of the buffer will be subtracted from all indexes (NxtFree, T0, T10, NxtClear) this is safe as NxtClear will always be the last index, as long as the number_of_entries*2 is less than the max positive integer that can be held by the index variables.

---

Optimization ideas:

* Let the expiry code run past T10 and potentially T0, as long as the entry being looked at is "In use" "Passive" (meaning the entry has been canceled). T10/T0 would then be moved along the way - this would keep the stored number of entries lower.












